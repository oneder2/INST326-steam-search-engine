# Steam Data Crawler Environment Variables
# Copy this file to .env and update the values as needed

# ============================================================================
# Steam API Configuration
# ============================================================================
STEAM_API_KEY=your-steam-api-key-here
STEAM_API_BASE_URL=https://api.steampowered.com
STEAM_STORE_API_URL=https://store.steampowered.com/api
STEAMSPY_API_URL=https://steamspy.com/api.php

# ============================================================================
# Database Configuration
# ============================================================================
DATABASE_PATH=data/games_data.db
DATABASE_BACKUP_PATH=data/backups/
DATABASE_POOL_SIZE=10
DATABASE_TIMEOUT=30

# ============================================================================
# Data Collection Configuration
# ============================================================================
BATCH_SIZE=100
RATE_LIMIT_DELAY=1.0
MAX_RETRIES=3
REQUEST_TIMEOUT=30
WORKER_THREADS=4
MAX_CONCURRENT_REQUESTS=10

# ============================================================================
# Data Processing Configuration
# ============================================================================
MIN_GAME_PRICE=0.0
MAX_GAME_PRICE=1000.0
MIN_DESCRIPTION_LENGTH=10
MAX_DESCRIPTION_LENGTH=5000
REQUIRED_FIELDS=app_id,title

# ============================================================================
# Search Index Configuration
# ============================================================================
FAISS_INDEX_PATH=data/game_embeddings.faiss
BM25_INDEX_PATH=data/bm25_index.pkl
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
INDEX_REBUILD_THRESHOLD=1000

# ============================================================================
# File Paths Configuration
# ============================================================================
RAW_DATA_PATH=data/raw/
PROCESSED_DATA_PATH=data/processed/
EXPORT_DATA_PATH=data/exports/
LOG_PATH=logs/
TEMP_PATH=temp/

# ============================================================================
# Logging Configuration
# ============================================================================
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE=crawler.log
LOG_MAX_SIZE=10485760
LOG_BACKUP_COUNT=5

# ============================================================================
# Performance Configuration
# ============================================================================
MEMORY_LIMIT=2048
DISK_SPACE_THRESHOLD=1024
CPU_USAGE_THRESHOLD=80
PROGRESS_REPORT_INTERVAL=100

# ============================================================================
# Data Quality Configuration
# ============================================================================
ENABLE_DATA_VALIDATION=true
SKIP_INVALID_GAMES=true
DUPLICATE_DETECTION=true
DATA_QUALITY_THRESHOLD=0.8

# ============================================================================
# Scheduling Configuration
# ============================================================================
FULL_CRAWL_INTERVAL=604800
UPDATE_CRAWL_INTERVAL=86400
INDEX_REBUILD_INTERVAL=259200
CLEANUP_INTERVAL=2592000

# ============================================================================
# Export Configuration
# ============================================================================
EXPORT_FORMAT=json
EXPORT_COMPRESSION=gzip
EXPORT_BATCH_SIZE=1000
INCLUDE_SCREENSHOTS=false

# ============================================================================
# Monitoring Configuration
# ============================================================================
ENABLE_METRICS=true
METRICS_PORT=9090
HEALTH_CHECK_PORT=8080
ALERT_EMAIL=admin@example.com

# ============================================================================
# Development Configuration
# ============================================================================
DEBUG=false
VERBOSE_LOGGING=false
DRY_RUN=false
SAMPLE_SIZE=0
FORCE_REPROCESS=false
